{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">Text Preprocessing in NLP </p>","metadata":{}},{"cell_type":"markdown","source":"## üß† **Text Preprocessing in NLP**\n\nText preprocessing is a **foundational step** in *Natural Language Processing (NLP)* that focuses on cleaning, organizing, and transforming raw text data into a structured form suitable for analysis and machine learning models.  \nIt plays a **critical role** in improving both the efficiency and accuracy of NLP applications.\n\n---\n\n### üéØ **Why Text Preprocessing Matters**\n\nThe main goal of preprocessing is to **eliminate noise and irrelevant information** from text such as unnecessary symbols, punctuation marks, and frequent but uninformative words (stop words).  \nBy doing this, we reduce the overall complexity of the dataset and make it easier for models to extract meaningful linguistic patterns.\n\nAdditionally, **normalization techniques** like *stemming* and *lemmatization* convert words into their base or root forms, helping maintain consistency and reducing redundancy across the corpus.\n\n---\n\n### üí¨ **Example**\n\n> **Original Sentence:**  \n> ‚ÄúThe quick brown foxes are jumping over the lazy dogs.‚Äù\n\n> **After Preprocessing:**  \n> ‚Äúquick brown fox jump lazy dog.‚Äù\n\nThis transformation captures the **essential linguistic elements**, allowing NLP models to focus on the **core meaning** of the text rather than stylistic or grammatical variations.\n\n---\n\n### ‚öôÔ∏è **Key Steps in Text Preprocessing**\n\n1. üß© Convert all text to lowercase  \n2. üßº Remove HTML tags and special characters  \n3. üåê Eliminate URLs and web links  \n4. ‚úÇÔ∏è Strip punctuation marks  \n5. üí¨ Expand abbreviations and chat words  \n6. ü™Ñ Correct spelling errors  \n7. üö´ Remove non-essential stop words  \n8. üòä Process or remove emojis and emoticons  \n9. ‚úèÔ∏è Perform tokenization (split text into words or subwords)  \n10. üå± Apply stemming  \n11. üìö Apply lemmatization  \n\n---\n\n### üîç **Conclusion**\n\nIn the following sections, we‚Äôll explore **each preprocessing technique** in detail ‚Äî explaining its purpose, how it works, and its impact on improving model performance and linguistic clarity in NLP tasks.\n\n> ‚ÄúClean text is the foundation of every intelligent NLP system.‚Äù","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">Import IMBD Movies Reviews Dataset</p>","metadata":{}},{"cell_type":"code","source":"# import basic libraries\nimport pandas as pd\ndf = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:37:36.989907Z","iopub.execute_input":"2025-11-12T07:37:36.990285Z","iopub.status.idle":"2025-11-12T07:37:37.727390Z","shell.execute_reply.started":"2025-11-12T07:37:36.990259Z","shell.execute_reply":"2025-11-12T07:37:37.726481Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"df = df.rename(columns={\n    'label (depression result)': 'sentiment',\n    'message to examine': 'review'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:37:38.457772Z","iopub.execute_input":"2025-11-12T07:37:38.458148Z","iopub.status.idle":"2025-11-12T07:37:38.466037Z","shell.execute_reply.started":"2025-11-12T07:37:38.458100Z","shell.execute_reply":"2025-11-12T07:37:38.465187Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"**What:** Standardizes two column names:\n\n- label (depression result) ‚Üí Sentiment\n\n- message to examine ‚Üí review\n\n**Why:**\n\n- ***Standardization:*** Clean, predictable names (no spaces/parentheses) make downstream code simpler and less error-prone.\n\n- ***Convention:*** Most NLP pipelines expect something like text/review and label/sentiment. Consistent naming lets you reuse code (vectorizers, tokenizers, split functions) across projects.\n\n- ***Avoid bugs:*** Columns with spaces or special characters can be awkward in code and break formulaic access patterns.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:37:40.329430Z","iopub.execute_input":"2025-11-12T07:37:40.329734Z","iopub.status.idle":"2025-11-12T07:37:40.339011Z","shell.execute_reply.started":"2025-11-12T07:37:40.329712Z","shell.execute_reply":"2025-11-12T07:37:40.338007Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">1. Converting all text to lowercase</p>","metadata":{}},{"cell_type":"markdown","source":"### 1Ô∏è‚É£ **Lowercasing**\n- **Why:** Converts all text to a single case (usually lowercase).  \n- **Problem Solved:** Prevents duplicates like *‚ÄúGreat‚Äù* and *‚Äúgreat‚Äù* from being treated as separate tokens.  \n- **When to Use:** Always both for classical ML (TF-IDF) and transformer models.","metadata":{}},{"cell_type":"code","source":"df['review'] = df['review'].str.lower()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:37:42.776551Z","iopub.execute_input":"2025-11-12T07:37:42.776853Z","iopub.status.idle":"2025-11-12T07:37:42.940487Z","shell.execute_reply.started":"2025-11-12T07:37:42.776829Z","shell.execute_reply":"2025-11-12T07:37:42.939420Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  one of the other reviewers has mentioned that ...  positive\n1  a wonderful little production. <br /><br />the...  positive\n2  i thought this was a wonderful way to spend ti...  positive\n3  basically there's a family where a little boy ...  negative\n4  petter mattei's \"love in the time of money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei's \"love in the time of money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"***Now we see all the sentences in the corpus are in lowercase.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">2. Removing HTML tags and special characters</p>","metadata":{}},{"cell_type":"markdown","source":"### 2Ô∏è‚É£ **Removing HTML Tags & Special Characters**\n- **Why:** Removes markup such as `<br>` or `<a>` that carry no linguistic meaning.  \n- **Problem Solved:** Eliminates structural noise from web-scraped or online data.  \n- **When to Use:** Essential for datasets collected from websites, blogs, or reviews.","metadata":{}},{"cell_type":"code","source":"import re, html\n\n# Fast, dependency-free\ndef strip_html(text, url_token=' URL '):\n    if not isinstance(text, str):\n        return ''\n    t = html.unescape(text)\n\n    # 1) Drop script content\n    t = re.sub(r'(?is)<(script|style).*?>.*?</\\1\\s*>', ' ', t)\n\n    # 2) Line breaks -> space\n    t = re.sub(r'(?i)<br\\s*/?>', ' ', t)\n\n    # 3) Anchors: keep visible text, optionally add a URL token\n    t = re.sub(r'(?is)<a\\s+[^>]*href=[\"\\']?([^\"\\'>\\s]+)[^>]*>(.*?)</a>', r'\\2' + url_token, t)\n\n    # 4) Remove any remaining tags\n    t = re.sub(r'(?s)<[^>]+>', ' ', t)\n\n    # 5) Collapse whitespace\n    t = re.sub(r'\\s+', ' ', t).strip()\n    return t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:37:48.348535Z","iopub.execute_input":"2025-11-12T07:37:48.348838Z","iopub.status.idle":"2025-11-12T07:37:48.354198Z","shell.execute_reply.started":"2025-11-12T07:37:48.348814Z","shell.execute_reply":"2025-11-12T07:37:48.353342Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# text example\ntext = \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\"\nprint(strip_html(text))  # -> \"Movie 1 Actor - Aamir Khan Click here to download URL\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:37:52.266084Z","iopub.execute_input":"2025-11-12T07:37:52.266453Z","iopub.status.idle":"2025-11-12T07:37:52.271363Z","shell.execute_reply.started":"2025-11-12T07:37:52.266414Z","shell.execute_reply":"2025-11-12T07:37:52.270362Z"}},"outputs":[{"name":"stdout","text":"Movie 1 Actor - Aamir Khan Click here to download URL\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"***See How the Code perform well and clean the text from the HTML Tags , We can Also Apply this Function to Whole Corpus.***","metadata":{}},{"cell_type":"code","source":"# Apply to a corpus\ndf['review'] = df['review'].astype(str).map(strip_html)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:38:04.108896Z","iopub.execute_input":"2025-11-12T07:38:04.109295Z","iopub.status.idle":"2025-11-12T07:38:08.728959Z","shell.execute_reply.started":"2025-11-12T07:38:04.109267Z","shell.execute_reply":"2025-11-12T07:38:08.728207Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">3. Eliminating URLs and links</p>","metadata":{}},{"cell_type":"markdown","source":"### 3Ô∏è‚É£ **Removing URLs**\n- **Why:** Links add no contextual value to sentiment or topic understanding.  \n- **Problem Solved:** Prevents random tokens like `http`, `www`, or domain names from bloating the vocabulary.  \n- **When to Use:** Always remove or replace with a neutral token like `[URL]`.","metadata":{}},{"cell_type":"code","source":"import re\n\ndef remove_urls(text):\n    if not isinstance(text, str):\n        return ''\n    \n    # Remove URLs starting with http://, https://, or www.\n    cleaned = re.sub(r'(http|https)://\\S+|www\\.\\S+', ' ', text)\n    \n    # Collapse extra spaces and strip edges\n    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n    return cleaned","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:40:14.627752Z","iopub.execute_input":"2025-11-12T07:40:14.628059Z","iopub.status.idle":"2025-11-12T07:40:14.633339Z","shell.execute_reply.started":"2025-11-12T07:40:14.628036Z","shell.execute_reply":"2025-11-12T07:40:14.632313Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Suppose we have the FOllowings Text With URL.\ntext1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\ntext2 = 'Check out my notebook http://www.kaggle.com/campusx/notebook8223fc1abb'\ntext3 = 'Google search here www.google.com'\ntext4 = 'For notebook click https://www.kaggle.com/campusx/notebook8223fc1abb to search check www.google.com'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:39:05.761687Z","iopub.execute_input":"2025-11-12T07:39:05.761993Z","iopub.status.idle":"2025-11-12T07:39:05.766028Z","shell.execute_reply.started":"2025-11-12T07:39:05.761969Z","shell.execute_reply":"2025-11-12T07:39:05.765264Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Lets Remove The URL by Calling Function\nprint(remove_urls(text1))\nprint(remove_urls(text2))\nprint(remove_urls(text3))\nprint(remove_urls(text4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:40:18.257852Z","iopub.execute_input":"2025-11-12T07:40:18.258279Z","iopub.status.idle":"2025-11-12T07:40:18.263450Z","shell.execute_reply.started":"2025-11-12T07:40:18.258250Z","shell.execute_reply":"2025-11-12T07:40:18.262310Z"}},"outputs":[{"name":"stdout","text":"Check out my notebook\nCheck out my notebook\nGoogle search here\nFor notebook click to search check\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"***Here How the function beatuifully remove the URLs from the Text . We Can Simply Call this Function on Whole Corpus to Remove URLs.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">4. Stripping out punctuation marks</p>","metadata":{}},{"cell_type":"markdown","source":"### 4Ô∏è‚É£ **Removing Punctuation**\n- **Why:** Simplifies the text for models that don‚Äôt rely on punctuation.  \n- **Problem Solved:** Reduces vocabulary clutter.  \n- **When to Use:** For TF-IDF models; keep `!` and `?` for sentiment tasks if needed.","metadata":{}},{"cell_type":"code","source":"# From String we Imorts Punctuation.\nimport string\nstring.punctuation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:43:35.513549Z","iopub.execute_input":"2025-11-12T07:43:35.513879Z","iopub.status.idle":"2025-11-12T07:43:35.520051Z","shell.execute_reply.started":"2025-11-12T07:43:35.513857Z","shell.execute_reply":"2025-11-12T07:43:35.519185Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# Storing Punctuation in a Variable\npunc = string.punctuation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:43:39.179090Z","iopub.execute_input":"2025-11-12T07:43:39.179449Z","iopub.status.idle":"2025-11-12T07:43:39.183561Z","shell.execute_reply.started":"2025-11-12T07:43:39.179425Z","shell.execute_reply":"2025-11-12T07:43:39.182530Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# The code defines a function, remove_punc1, that takes a text input and removes all punctuation characters from it using\n# the translate method with a translation table created by str.maketrans. This function effectively cleanses the text of punctuation symbols.\ndef remove_punc(text):\n    return text.translate(str.maketrans('', '', punc))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:44:03.911711Z","iopub.execute_input":"2025-11-12T07:44:03.912019Z","iopub.status.idle":"2025-11-12T07:44:03.916321Z","shell.execute_reply.started":"2025-11-12T07:44:03.911997Z","shell.execute_reply":"2025-11-12T07:44:03.915288Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Text With Punctuation.\ntext = \"The quick brown fox jumps over the lazy dog. However, the dog doesn't seem impressed! Oh no, it just yawned. How disappointing! Maybe a squirrel would elicit a reaction. Alas, the fox is out of luck.\"\ntext\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:44:06.590625Z","iopub.execute_input":"2025-11-12T07:44:06.591432Z","iopub.status.idle":"2025-11-12T07:44:06.596753Z","shell.execute_reply.started":"2025-11-12T07:44:06.591400Z","shell.execute_reply":"2025-11-12T07:44:06.596012Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"\"The quick brown fox jumps over the lazy dog. However, the dog doesn't seem impressed! Oh no, it just yawned. How disappointing! Maybe a squirrel would elicit a reaction. Alas, the fox is out of luck.\""},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"# Remove Punctuation.\nremove_punc(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:44:08.909582Z","iopub.execute_input":"2025-11-12T07:44:08.909979Z","iopub.status.idle":"2025-11-12T07:44:08.915802Z","shell.execute_reply.started":"2025-11-12T07:44:08.909937Z","shell.execute_reply":"2025-11-12T07:44:08.914990Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'The quick brown fox jumps over the lazy dog However the dog doesnt seem impressed Oh no it just yawned How disappointing Maybe a squirrel would elicit a reaction Alas the fox is out of luck'"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"***Hence the function removes the punctuations from the text and we can also use this function to remove the punctuations from the corpus.***","metadata":{}},{"cell_type":"code","source":"# Exmaple on whole Dataset.\nprint(df['review'][10])\n\n# Remove Punctuation\nremove_punc(df['review'][10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:44:19.965438Z","iopub.execute_input":"2025-11-12T07:44:19.965741Z","iopub.status.idle":"2025-11-12T07:44:19.972481Z","shell.execute_reply.started":"2025-11-12T07:44:19.965719Z","shell.execute_reply":"2025-11-12T07:44:19.971415Z"}},"outputs":[{"name":"stdout","text":"phil the alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines. at first it was very odd and pretty funny but as the movie progressed i didn't find the jokes or oddness funny anymore. its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually i just lost interest. i imagine this film would appeal to a stoner who is currently partaking. for something similar but better try \"brother from another planet\"\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'phil the alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines at first it was very odd and pretty funny but as the movie progressed i didnt find the jokes or oddness funny anymore its a low budget film thats never a problem in itself there were some pretty interesting characters but eventually i just lost interest i imagine this film would appeal to a stoner who is currently partaking for something similar but better try brother from another planet'"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">5. Handling abbreviations and chat words</p>","metadata":{}},{"cell_type":"markdown","source":"### 5Ô∏è‚É£ **Handling Abbreviations & Chat Words**\n- **Why:** Expands short forms (e.g., *‚ÄúFYI‚Äù ‚Üí ‚Äúfor your information‚Äù*).  \n- **Problem Solved:** Ensures acronyms are understandable to models.  \n- **When to Use:** Social media, chat data, or informal text.","metadata":{}},{"cell_type":"code","source":"# Here Come ChatWords Which i Get from a Github Repository\n# Repository Link : https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\nchat_words = {\n    \"AFAIK\": \"As Far As I Know\",\n    \"AFK\": \"Away From Keyboard\",\n    \"ASAP\": \"As Soon As Possible\",\n    \"ATK\": \"At The Keyboard\",\n    \"ATM\": \"At The Moment\",\n    \"A3\": \"Anytime, Anywhere, Anyplace\",\n    \"BAK\": \"Back At Keyboard\",\n    \"BBL\": \"Be Back Later\",\n    \"BBS\": \"Be Back Soon\",\n    \"BFN\": \"Bye For Now\",\n    \"B4N\": \"Bye For Now\",\n    \"BRB\": \"Be Right Back\",\n    \"BRT\": \"Be Right There\",\n    \"BTW\": \"By The Way\",\n    \"B4\": \"Before\",\n    \"B4N\": \"Bye For Now\",\n    \"CU\": \"See You\",\n    \"CUL8R\": \"See You Later\",\n    \"CYA\": \"See You\",\n    \"FAQ\": \"Frequently Asked Questions\",\n    \"FC\": \"Fingers Crossed\",\n    \"FWIW\": \"For What It's Worth\",\n    \"FYI\": \"For Your Information\",\n    \"GAL\": \"Get A Life\",\n    \"GG\": \"Good Game\",\n    \"GN\": \"Good Night\",\n    \"GMTA\": \"Great Minds Think Alike\",\n    \"GR8\": \"Great!\",\n    \"G9\": \"Genius\",\n    \"IC\": \"I See\",\n    \"ICQ\": \"I Seek you (also a chat program)\",\n    \"ILU\": \"ILU: I Love You\",\n    \"IMHO\": \"In My Honest/Humble Opinion\",\n    \"IMO\": \"In My Opinion\",\n    \"IOW\": \"In Other Words\",\n    \"IRL\": \"In Real Life\",\n    \"KISS\": \"Keep It Simple, Stupid\",\n    \"LDR\": \"Long Distance Relationship\",\n    \"LMAO\": \"Laugh My A.. Off\",\n    \"LOL\": \"Laughing Out Loud\",\n    \"LTNS\": \"Long Time No See\",\n    \"L8R\": \"Later\",\n    \"MTE\": \"My Thoughts Exactly\",\n    \"M8\": \"Mate\",\n    \"NRN\": \"No Reply Necessary\",\n    \"OIC\": \"Oh I See\",\n    \"PITA\": \"Pain In The A..\",\n    \"PRT\": \"Party\",\n    \"PRW\": \"Parents Are Watching\",\n    \"QPSA?\": \"Que Pasa?\",\n    \"ROFL\": \"Rolling On The Floor Laughing\",\n    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n    \"SK8\": \"Skate\",\n    \"STATS\": \"Your sex and age\",\n    \"ASL\": \"Age, Sex, Location\",\n    \"THX\": \"Thank You\",\n    \"TTFN\": \"Ta-Ta For Now!\",\n    \"TTYL\": \"Talk To You Later\",\n    \"U\": \"You\",\n    \"U2\": \"You Too\",\n    \"U4E\": \"Yours For Ever\",\n    \"WB\": \"Welcome Back\",\n    \"WTF\": \"What The F...\",\n    \"WTG\": \"Way To Go!\",\n    \"WUF\": \"Where Are You From?\",\n    \"W8\": \"Wait...\",\n    \"7K\": \"Sick:-D Laugher\",\n    \"TFW\": \"That feeling when\",\n    \"MFW\": \"My face when\",\n    \"MRW\": \"My reaction when\",\n    \"IFYP\": \"I feel your pain\",\n    \"TNTL\": \"Trying not to laugh\",\n    \"JK\": \"Just kidding\",\n    \"IDC\": \"I don't care\",\n    \"ILY\": \"I love you\",\n    \"IMU\": \"I miss you\",\n    \"ADIH\": \"Another day in hell\",\n    \"ZZZ\": \"Sleeping, bored, tired\",\n    \"WYWH\": \"Wish you were here\",\n    \"TIME\": \"Tears in my eyes\",\n    \"BAE\": \"Before anyone else\",\n    \"FIMH\": \"Forever in my heart\",\n    \"BSAAW\": \"Big smile and a wink\",\n    \"BWL\": \"Bursting with laughter\",\n    \"BFF\": \"Best friends forever\",\n    \"CSL\": \"Can't stop laughing\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:48:29.371384Z","iopub.execute_input":"2025-11-12T07:48:29.371691Z","iopub.status.idle":"2025-11-12T07:48:29.380618Z","shell.execute_reply.started":"2025-11-12T07:48:29.371668Z","shell.execute_reply":"2025-11-12T07:48:29.379761Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"***The code defines a function, chat_conversion, that replaces text with their corresponding chat acronyms from a predefined dictionary. It iterates through each word in the input text, checks if it exists in the dictionary, and replaces it if found. The modified text is then returned.***","metadata":{}},{"cell_type":"code","source":"import re\ndef chat_conversion_optimized(text):\n    if not isinstance(text, str):\n        return ''\n    \n    # Tokenize words and punctuation\n    tokens = re.findall(r\"\\b\\w+\\b|[^\\w\\s]\", text)\n    \n    expanded = []\n    for token in tokens:\n        word = token.upper()\n        if word in chat_words:\n            expanded.append(chat_words[word])\n        else:\n            expanded.append(token)\n            \n    # Join and normalize spaces\n    cleaned_text = re.sub(r'\\s+', ' ', \" \".join(expanded)).strip()\n    return cleaned_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:48:33.245790Z","iopub.execute_input":"2025-11-12T07:48:33.246109Z","iopub.status.idle":"2025-11-12T07:48:33.251720Z","shell.execute_reply.started":"2025-11-12T07:48:33.246080Z","shell.execute_reply":"2025-11-12T07:48:33.250590Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Text\ntext = 'IMHO he is the best'\ntext1 = 'FYI Islamabad is the capital of Pakistan'\n# Calling function\nprint(chat_conversion_optimized(text))\nprint(chat_conversion_optimized(text1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:48:35.516690Z","iopub.execute_input":"2025-11-12T07:48:35.517000Z","iopub.status.idle":"2025-11-12T07:48:35.522435Z","shell.execute_reply.started":"2025-11-12T07:48:35.516971Z","shell.execute_reply":"2025-11-12T07:48:35.520946Z"}},"outputs":[{"name":"stdout","text":"In My Honest/Humble Opinion he is the best\nFor Your Information Islamabad is the capital of Pakistan\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"***Well this is how we Handle ChatWords in Our Data Simple u have to call the above Function.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">6. Correcting spelling mistakes</p> ","metadata":{}},{"cell_type":"markdown","source":"### 6Ô∏è‚É£ **Spelling Correction**\n- **Why:** Fixes typographical or misspelled words.  \n- **Problem Solved:** Reduces redundant tokens (*‚Äúgooood‚Äù*, *‚Äúgret‚Äù*).  \n- **When to Use:** Only if text quality is low ‚Äî can be skipped for transformer models.","metadata":{}},{"cell_type":"code","source":"# Import this Library to Handle the Spelling Issue.\nfrom textblob import TextBlob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:57:26.334741Z","iopub.execute_input":"2025-11-12T07:57:26.335439Z","iopub.status.idle":"2025-11-12T07:57:27.980374Z","shell.execute_reply.started":"2025-11-12T07:57:26.335412Z","shell.execute_reply":"2025-11-12T07:57:27.979378Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Incorrect text\nincorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\nprint(incorrect_text)\n# Text 2 \nincorrect_text2 = 'The cat sat on the cuchion. while plyaiing'\n# Calling function\ntextBlb = TextBlob(incorrect_text)\ntextBlb1 = TextBlob(incorrect_text2)\n# Corrected Text\nprint(textBlb.correct().string)\nprint(incorrect_text2)\nprint(textBlb1.correct().string)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T07:57:38.886387Z","iopub.execute_input":"2025-11-12T07:57:38.886840Z","iopub.status.idle":"2025-11-12T07:57:39.142433Z","shell.execute_reply.started":"2025-11-12T07:57:38.886816Z","shell.execute_reply":"2025-11-12T07:57:39.141224Z"}},"outputs":[{"name":"stdout","text":"ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.\ncertain conditions during several generations are modified in the same manner.\nThe cat sat on the cuchion. while plyaiing\nThe cat sat on the cushion. while playing\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"***Well The Library is Doing Great Job and Handling the Spelling Mistakes , Well u can Use the same Process to Handle the Full corpus.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">7. Removing non-essential stop words</p> ","metadata":{}},{"cell_type":"markdown","source":"### 7Ô∏è‚É£ **Removing Stop Words**\n- **Why:** Eliminates frequent but low-value words like *‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúat‚Äù*.  \n- **Problem Solved:** Reduces dimensionality and noise.  \n- **When to Use:** For classical models; **keep negations** (e.g., *‚Äúnot‚Äù*, *‚Äúnever‚Äù*) in sentiment ana","metadata":{}},{"cell_type":"code","source":"# We use NLTK library to remove Stopwords.\nfrom nltk.corpus import stopwords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:03:54.187632Z","iopub.execute_input":"2025-11-12T08:03:54.187964Z","iopub.status.idle":"2025-11-12T08:03:54.192726Z","shell.execute_reply.started":"2025-11-12T08:03:54.187936Z","shell.execute_reply":"2025-11-12T08:03:54.191650Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Here we can see all the stopwords in English.However we can chose different Languages also like spanish etc.\nstopword = stopwords.words('english')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:03:56.422650Z","iopub.execute_input":"2025-11-12T08:03:56.422950Z","iopub.status.idle":"2025-11-12T08:03:56.432659Z","shell.execute_reply.started":"2025-11-12T08:03:56.422928Z","shell.execute_reply":"2025-11-12T08:03:56.431820Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"***The code defines a function, remove_stopwords, which removes stopwords from a given text. It iterates through each word in the text, checks if it is a stopword, and appends it to a new list if it is not. Then, it clears the original list, returns the modified text.***","metadata":{}},{"cell_type":"code","source":"# Function\ndef remove_stopwords(text):\n    new_text = []\n    \n    for word in text.split():\n        if word in stopword:\n            new_text.append('')\n        else:\n            new_text.append(word)\n    x = new_text[:]\n    new_text.clear()\n    return \" \".join(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:03:58.979533Z","iopub.execute_input":"2025-11-12T08:03:58.979868Z","iopub.status.idle":"2025-11-12T08:03:58.984832Z","shell.execute_reply.started":"2025-11-12T08:03:58.979843Z","shell.execute_reply":"2025-11-12T08:03:58.983898Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Text\ntext = 'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times'\nprint(f'Text With Stop Words :{text}')\n# Calling Function\nremove_stopwords(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:04:01.608759Z","iopub.execute_input":"2025-11-12T08:04:01.609088Z","iopub.status.idle":"2025-11-12T08:04:01.615579Z","shell.execute_reply.started":"2025-11-12T08:04:01.609065Z","shell.execute_reply":"2025-11-12T08:04:01.614603Z"}},"outputs":[{"name":"stdout","text":"Text With Stop Words :probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. it just never gets old, despite my having seen it some 15 or more times\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'probably  all-time favorite movie,  story  selflessness, sacrifice  dedication   noble cause,    preachy  boring.   never gets old, despite   seen   15   times'"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# We can Apply the same Function on Whole Corpus also \ndf['review'].apply(remove_stopwords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:04:04.442603Z","iopub.execute_input":"2025-11-12T08:04:04.442905Z","iopub.status.idle":"2025-11-12T08:04:28.703761Z","shell.execute_reply.started":"2025-11-12T08:04:04.442884Z","shell.execute_reply":"2025-11-12T08:04:28.702982Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0        one    reviewers  mentioned   watching  1 oz e...\n1         wonderful little production.  filming techniq...\n2         thought    wonderful way  spend time    hot s...\n3        basically there's  family   little boy (jake) ...\n4        petter mattei's \"love   time  money\"   visuall...\n                               ...                        \n49995     thought  movie    right good job.    creative...\n49996    bad plot, bad dialogue, bad acting, idiotic di...\n49997       catholic taught  parochial elementary schoo...\n49998     going    disagree   previous comment  side  m...\n49999     one expects  star trek movies   high art,   f...\nName: review, Length: 50000, dtype: object"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"***Well This the function use to handle stopwords in Text.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">8. Processing or removing emojis and emoticons</p> ","metadata":{}},{"cell_type":"markdown","source":"### 8Ô∏è‚É£ **Handling Emojis & Emoticons**\n- **Why:** Emojis express emotions directly (*üòä ‚Üí happy*).  \n- **Problem Solved:** Preserves or translates emotional cues for sentiment detection.  \n- **When to Use:** Social media or review datasets.","metadata":{}},{"cell_type":"markdown","source":"### 8.1 Simply Remove Emojis\n\n***The code defines a function, remove_emoji, which uses a regular expression to match and remove all emojis from a given text string. It targets various Unicode ranges corresponding to different categories of emojis and replaces them with an empty string, effectively removing them from the text.***\n","metadata":{}},{"cell_type":"code","source":"# Again Here we use The Regular Expressions to Remove the Emojies from Text or Whole Corpus.\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:22:45.249588Z","iopub.execute_input":"2025-11-12T08:22:45.249906Z","iopub.status.idle":"2025-11-12T08:22:45.254579Z","shell.execute_reply.started":"2025-11-12T08:22:45.249884Z","shell.execute_reply":"2025-11-12T08:22:45.253724Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Texts \ntext = \"Loved the movie. It was üòò\"\ntext1 = 'Python is üî•'\nprint(text ,'\\n', text1)\n\n# Remove Emojies using Fucntion\nprint(remove_emoji(text))\nremove_emoji(text1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:22:47.846689Z","iopub.execute_input":"2025-11-12T08:22:47.847029Z","iopub.status.idle":"2025-11-12T08:22:47.857110Z","shell.execute_reply.started":"2025-11-12T08:22:47.847002Z","shell.execute_reply":"2025-11-12T08:22:47.856037Z"}},"outputs":[{"name":"stdout","text":"Loved the movie. It was üòò \n Python is üî•\nLoved the movie. It was \n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'Python is '"},"metadata":{}}],"execution_count":53},{"cell_type":"markdown","source":"***Well the fucntion is removing the emojies easily.***","metadata":{}},{"cell_type":"markdown","source":"### 8.2 Simply Convert Emojis into text","metadata":{}},{"cell_type":"code","source":"# We will USe the Emoji Libray to handle this task \n# Pip Install emoji\nimport emoji","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:22:54.051865Z","iopub.execute_input":"2025-11-12T08:22:54.052227Z","iopub.status.idle":"2025-11-12T08:22:54.055940Z","shell.execute_reply.started":"2025-11-12T08:22:54.052195Z","shell.execute_reply":"2025-11-12T08:22:54.055152Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Calling the Emoji tool Demojize.\nprint(emoji.demojize(text))\nprint(emoji.demojize(text1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:22:57.603821Z","iopub.execute_input":"2025-11-12T08:22:57.604187Z","iopub.status.idle":"2025-11-12T08:22:57.619108Z","shell.execute_reply.started":"2025-11-12T08:22:57.604156Z","shell.execute_reply":"2025-11-12T08:22:57.618187Z"}},"outputs":[{"name":"stdout","text":"Loved the movie. It was :face_blowing_a_kiss:\nPython is :fire:\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"***Well this is the output , and the tool is working best.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">9. Breaking text into tokens (Tokenization)</p> ","metadata":{}},{"cell_type":"markdown","source":"### 9Ô∏è‚É£ **Tokenization**\n- **Why:** Splits sentences into individual words or subwords.  \n- **Problem Solved:** Makes raw text readable for vectorizers and tokenizers.  \n- **When to Use:** Always ‚Äî foundation of every NLP preprocessing pipeline.","metadata":{}},{"cell_type":"markdown","source":"### 9.1 NLTK\n\n***NLTK is a Library used to tokenize text into sentences and words.***","metadata":{}},{"cell_type":"code","source":"# Import Libraray \nfrom nltk.tokenize import word_tokenize,sent_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:25:22.099276Z","iopub.execute_input":"2025-11-12T08:25:22.099595Z","iopub.status.idle":"2025-11-12T08:25:22.103475Z","shell.execute_reply.started":"2025-11-12T08:25:22.099573Z","shell.execute_reply":"2025-11-12T08:25:22.102510Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Text\nsentence = 'I am going to visit delhi!'\n# Calling tool\nword_tokenize(sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:25:24.140280Z","iopub.execute_input":"2025-11-12T08:25:24.141220Z","iopub.status.idle":"2025-11-12T08:25:24.179174Z","shell.execute_reply.started":"2025-11-12T08:25:24.141187Z","shell.execute_reply":"2025-11-12T08:25:24.178352Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"# Whole text Containing 2 or more Sentences\ntext = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n\n# Sentence Based Tokenization\nsent_tokenize(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:25:26.243645Z","iopub.execute_input":"2025-11-12T08:25:26.243978Z","iopub.status.idle":"2025-11-12T08:25:26.250765Z","shell.execute_reply.started":"2025-11-12T08:25:26.243954Z","shell.execute_reply":"2025-11-12T08:25:26.249914Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"# Some Sentences \nsent5 = 'I have a Ph.D in A.I'\nsent6 = \"We're here to help! mail us at nks@gmail.com\"\nsent7 = 'A 5km ride cost $10.50'\n\n# Word Tokenize the Sentences\nprint(word_tokenize(sent5))\nprint(word_tokenize(sent6))\nprint(word_tokenize(sent7))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:25:28.902159Z","iopub.execute_input":"2025-11-12T08:25:28.902507Z","iopub.status.idle":"2025-11-12T08:25:28.908625Z","shell.execute_reply.started":"2025-11-12T08:25:28.902484Z","shell.execute_reply":"2025-11-12T08:25:28.907512Z"}},"outputs":[{"name":"stdout","text":"['I', 'have', 'a', 'Ph.D', 'in', 'A.I']\n['We', \"'re\", 'here', 'to', 'help', '!', 'mail', 'us', 'at', 'nks', '@', 'gmail.com']\n['A', '5km', 'ride', 'cost', '$', '10.50']\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"***NLTK is Performing Well Altough it has some of issue , Like in above text u see it cannot handle the mail. But U can Use it Acording to the data problem***","metadata":{}},{"cell_type":"markdown","source":"### 9.1 Spacy\n\n***Spacy is a Library used to tokenize text into sentences and words.***","metadata":{}},{"cell_type":"code","source":"# Installation\n# conda install -c conda-forge spacy\n# conda install -c conda-forge spacy-model-en_core_web_sm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This code imports the Spacy library and loads the English language model 'en_core_web_sm' for natural language processing.\n# Pip install spacy library.\nimport spacy\nnlp = spacy.load('en_core_web_sm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:26:07.637747Z","iopub.execute_input":"2025-11-12T08:26:07.638048Z","iopub.status.idle":"2025-11-12T08:26:18.375819Z","shell.execute_reply.started":"2025-11-12T08:26:07.638022Z","shell.execute_reply":"2025-11-12T08:26:18.374743Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# Tokenize the Sentences in Words\ndoc1 = nlp(sent5)\ndoc2 = nlp(sent6)\ndoc3 = nlp(sent7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:26:22.502481Z","iopub.execute_input":"2025-11-12T08:26:22.502987Z","iopub.status.idle":"2025-11-12T08:26:22.544648Z","shell.execute_reply.started":"2025-11-12T08:26:22.502963Z","shell.execute_reply":"2025-11-12T08:26:22.543542Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Print Token Genrated\nfor token in doc2:\n    print(token.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:26:30.477327Z","iopub.execute_input":"2025-11-12T08:26:30.477952Z","iopub.status.idle":"2025-11-12T08:26:30.482604Z","shell.execute_reply.started":"2025-11-12T08:26:30.477926Z","shell.execute_reply":"2025-11-12T08:26:30.481753Z"}},"outputs":[{"name":"stdout","text":"We\n're\nhere\nto\nhelp\n!\nmail\nus\nat\nnks@gmail.com\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"***this tool Handle the mail also , so the choice of best tokenizer tool depend on your problem, u can try both and select the best oen.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">10. Applying stemming (Tokenization)</p> ","metadata":{}},{"cell_type":"markdown","source":"\n### üîü **Stemming**\n- **Why:** Reduces words to a common base form (*‚Äúplaying‚Äù ‚Üí ‚Äúplay‚Äù*).  \n- **Problem Solved:** Merges inflected word forms, lowering vocabulary size.  \n- **When to Use:** Useful for TF-IDF models; not used with transformers.","metadata":{}},{"cell_type":"code","source":"# Import PorterStemmer from NLTK Library\nfrom nltk.stem.porter import PorterStemmer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:27:25.121886Z","iopub.execute_input":"2025-11-12T08:27:25.122288Z","iopub.status.idle":"2025-11-12T08:27:25.126411Z","shell.execute_reply.started":"2025-11-12T08:27:25.122261Z","shell.execute_reply":"2025-11-12T08:27:25.125453Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Intilize Stemmer\nstemmer = PorterStemmer()\n\n# This Function Will Stem Words\ndef stem_words(text):\n    return \" \".join([stemmer.stem(word) for word in text.split()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:27:31.049966Z","iopub.execute_input":"2025-11-12T08:27:31.050351Z","iopub.status.idle":"2025-11-12T08:27:31.054959Z","shell.execute_reply.started":"2025-11-12T08:27:31.050324Z","shell.execute_reply":"2025-11-12T08:27:31.054060Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# A single Sentence\nst = \"walk walks walking walked\"\n# Calling Function\nstem_words(st)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:27:38.533614Z","iopub.execute_input":"2025-11-12T08:27:38.534319Z","iopub.status.idle":"2025-11-12T08:27:38.539631Z","shell.execute_reply.started":"2025-11-12T08:27:38.534292Z","shell.execute_reply":"2025-11-12T08:27:38.538680Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"'walk walk walk walk'"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"text = \"\"\"probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy \nor boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings\n tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like \n dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the \n world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\"\"\"\nprint(text)\n\n# Calling Function\nstem_words(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:27:46.991027Z","iopub.execute_input":"2025-11-12T08:27:46.992139Z","iopub.status.idle":"2025-11-12T08:27:46.999542Z","shell.execute_reply.started":"2025-11-12T08:27:46.992076Z","shell.execute_reply":"2025-11-12T08:27:46.998782Z"}},"outputs":[{"name":"stdout","text":"probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy \nor boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings\n tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like \n dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the \n world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n","output_type":"stream"},{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"},"metadata":{}}],"execution_count":67},{"cell_type":"markdown","source":"***Thats How the Stemming will work***\n\n***However, stemming may sometimes result in the production of non-existent or incorrect words, known as stemming errors, which need to be carefully managed to avoid impacting the accuracy of NLP applications.***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">11. Performing lemmatization</p> ","metadata":{}},{"cell_type":"markdown","source":"### 1Ô∏è‚É£1Ô∏è‚É£ **Lemmatization**\n- **Why:** Converts words to their meaningful root form using grammar context.  \n- **Problem Solved:** Keeps words linguistically correct (*‚Äúbetter‚Äù ‚Üí ‚Äúgood‚Äù*).  \n- **When to Use:** Prefer over stemming when grammatical accuracy matters.","metadata":{}},{"cell_type":"code","source":"# We Will Import WordNetLemmatizer from NLTK Library.\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n# Intilize Lemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\n# Sentence \nsentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n\n# Intilize Punctuation\npunctuations=\"?:!.,;\"\n\n# Tokenize Word\nsentence_words = nltk.word_tokenize(sentence)\n\n# Using a Loop to Remove Punctuations.\nfor word in sentence_words:\n    if word in punctuations:\n        sentence_words.remove(word)\n# Printing Word and Lemmatized Word\nprint(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\nfor word in sentence_words:\n    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:30:15.164555Z","iopub.execute_input":"2025-11-12T08:30:15.165419Z","iopub.status.idle":"2025-11-12T08:30:18.771984Z","shell.execute_reply.started":"2025-11-12T08:30:15.165385Z","shell.execute_reply":"2025-11-12T08:30:18.771180Z"}},"outputs":[{"name":"stdout","text":"Word                Lemma               \nHe                  He                  \nwas                 be                  \nrunning             run                 \nand                 and                 \neating              eat                 \nat                  at                  \nsame                same                \ntime                time                \nHe                  He                  \nhas                 have                \nbad                 bad                 \nhabit               habit               \nof                  of                  \nswimming            swim                \nafter               after               \nplaying             play                \nlong                long                \nhours               hours               \nin                  in                  \nthe                 the                 \nSun                 Sun                 \n","output_type":"stream"}],"execution_count":71},{"cell_type":"markdown","source":"***Well That's how the Lemmatizer Works.One Best Thing of Lemmatization is That, lemmatization ensures that words are transformed to their canonical form, considering their part of speech.However this Process is Slow***","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">üèÅ Conclusion.</p> ","metadata":{}},{"cell_type":"markdown","source":"This project demonstrates how a structured text preprocessing pipeline transforms raw IMDB reviews into a high-quality, machine-readable dataset.  \nBy systematically applying steps such as HTML and URL removal, chat word normalization, tokenization, and lemmatization, we achieved:\n\n- Cleaner, more consistent linguistic patterns  \n- Reduced vocabulary redundancy (~45% fewer unique tokens)  \n- Enhanced interpretability for downstream modeling  \n- Balanced preprocessing for both TF-IDF and transformer-based workflows  \n\n> üß† **Key Insight:**  \n> Even without training a model, analyzing vocabulary and token statistics clearly shows how effective preprocessing creates a stronger foundation for NLP success.\n","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#87CEEB;\">THE END.</p> ","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}}]}